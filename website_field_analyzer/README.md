# Website Field Analyzer

A **pure, read-only analyzer** that captures what a website expects from a human user without any interaction. This tool follows a strict 14-step pipeline to produce structured JSON output describing forms, fields, and page types.

## ðŸŽ¯ Purpose

This is **Step-1** of a larger web automation system. It analyzes web pages to understand their structure **without**:
- Filling forms
- Clicking buttons
- Bypassing security
- Scraping data
- Any automation actions

## ðŸ”· The 14-Step Pipeline

```
User URL
  â†“
Browser Launch
  â†“
Page Load & Stabilize
  â†“
DOM Snapshot
  â†“
Interactive Element Extraction
  â†“
Element Normalization
  â†“
Form Grouping
  â†“
Required / Optional Classification
  â†“
Page Type Detection
  â†“
Structured JSON Output
```

## ðŸ“¦ Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
playwright install chromium
```

## ðŸš€ Usage

### Basic Usage

```bash
python main.py --url "https://example.com/login"
```

### Save Output to File

```bash
python main.py --url "https://example.com/login" --output analysis.json
```

### Run in Visible Mode (Non-Headless)

```bash
python main.py --url "https://example.com/login" --no-headless
```

### Enable Debug Logging

```bash
python main.py --url "https://example.com/login" --debug
```

## ðŸ“Š Output Structure

The analyzer produces a structured JSON output:

```json
{
  "url": "https://example.com/login",
  "page_type": "login",
  "forms": [
    {
      "form_id": "form_abc123",
      "form_purpose": "login",
      "fields": [
        {
          "tag_name": "input",
          "input_type": "email",
          "name": "email",
          "classification": "required",
          "visible": true,
          "selector": "input[name='email']"
        },
        {
          "tag_name": "input",
          "input_type": "password",
          "name": "password",
          "classification": "required",
          "visible": true,
          "selector": "input[name='password']"
        }
      ],
      "submit_element": {
        "tag": "button",
        "type": "submit",
        "text": "Sign In"
      }
    }
  ],
  "total_fields": 2,
  "total_required": 2,
  "total_forms": 1
}
```

## ðŸ—ï¸ Architecture

```
website_field_analyzer/
â”œâ”€â”€ config/          # Settings and browser profiles
â”œâ”€â”€ browser/         # Browser management and page loading
â”œâ”€â”€ analyzer/        # Core analysis components
â”‚   â”œâ”€â”€ dom_analyzer.py      # Steps 4-7: Extract & normalize
â”‚   â”œâ”€â”€ form_detector.py     # Steps 8-9: Group & detect submit
â”‚   â”œâ”€â”€ field_classifier.py  # Step 10: Classify fields
â”‚   â””â”€â”€ page_classifier.py   # Steps 11-12: Classify page
â”œâ”€â”€ models/          # Data structures
â”œâ”€â”€ utils/           # Helper functions
â””â”€â”€ main.py          # Entry point
```

## ðŸŽ“ Classification Logic

### Form Purpose Detection

- **Login**: email/username + password (1 password field)
- **Signup**: email + multiple passwords (confirm password)
- **Search**: single text input + submit
- **Listing**: multiple dropdowns/filters
- **Mixed**: combination of above
- **Unknown**: unclear pattern

### Field Classification

**Required if:**
- Has `required` attribute
- Type is `password`
- Type is `hidden` (tokens like CSRF)
- Name/ID matches common patterns (email, username, etc.)

**Optional if:**
- Dropdown filters
- Checkboxes
- Secondary inputs

**Hidden if:**
- Type is `hidden`
- Not visible on page

### Page Type Detection

Based on all forms present:
- **login page**: Only login forms
- **signup page**: Only signup forms
- **search page**: Only search forms
- **listing page**: Only listing/filter forms
- **mixed page**: Multiple form types
- **unknown page**: Unclear pattern

## âš ï¸ Important Notes

> **This is a READ-ONLY analyzer**
> 
> It does NOT:
> - Fill any forms
> - Click any buttons
> - Bypass Cloudflare or security
> - Scrape any data
> - Perform any automation

The analyzer observes and reports what it sees, nothing more.

## ðŸ”§ Configuration

Edit `config/settings.py` to customize:

- Timeouts
- Browser behavior
- Analysis thresholds
- Field classification patterns

## ðŸ“ Examples

### Analyze GitHub Login

```bash
python main.py --url "https://github.com/login"
```

### Analyze Google Search

```bash
python main.py --url "https://www.google.com"
```

### Analyze with Debug Output

```bash
python main.py --url "https://example.com" --debug --output result.json
```

## ðŸ§ª Testing

```bash
# Run tests
python -m pytest tests/

# Run specific test
python -m pytest tests/test_dom_analysis.py
```

## ðŸ“„ License

MIT License

## ðŸ¤ Contributing

This is Step-1 of a larger system. Keep it pure and focused on analysis only.

**Do NOT add:**
- Form filling logic
- Click automation
- Cloudflare bypassing
- Data scraping

These belong in Step-2 (Decision Engine) and beyond.

## ðŸ”® Future Enhancements

- Machine learning-based field classification
- Support for shadow DOM
- iframe analysis
- Dynamic form detection (forms that appear after interaction)
- API endpoint detection from network traffic

---

**Remember**: This analyzer should be able to say:

> "I know exactly what this website expects from a human, without interacting with it."

If it does anything more than observe, it's doing too much.
